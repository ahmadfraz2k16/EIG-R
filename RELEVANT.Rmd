# IMPORTING 
```{r}
library(readxl)
library(tidyverse)
# load the data.table package
library(data.table)
# load the dplyr package
library(dplyr)
# load magrittr or dplyr package
library(magrittr)
# Load the lubridate package
library(lubridate)

```
# processing for all files
```{r running but paused for a while, eval=FALSE, include=FALSE}
# Start measuring time
start_time <- Sys.time()

# Create an empty global data frame
global_df <- data.frame(Time = character(), Name = character(), Energy_MWh = numeric())

process_mw_sheets <- function(fetched_file_name, fetched_date) {
  # READING EXCEL FILE
  file_date<-fetched_date
  filename<-fetched_file_name
  # filename<-"02 MARCH 2K22.xlsm"
  # Read the Excel file
  file_path <-"C:/Users/python/Documents/projR/MAR-2022/"
  df <- read_excel(file.path(file_path, filename), sheet = "MW", range = "A4:Y311")
  # df <- read_excel(filename, sheet = "MW", range = "A4:Y311")
  # Applying Basic Cleaning
  #remove rows containing FUT
  df<-df[-grep("FUT", df$HYDEL.), ]
  # before removing spaces
  #count the number of characters in the first column before trimming
  nchar(df$HYDEL.)
  # removing rows which are other than power plants
  trim <- function( x ) {
    gsub("(^[[:space:]]+|[[:space:]]+$)", "", x)
  }
  # removing leading & trailing spaces from all columns
  df_trimmed <- df %>% mutate(across(everything(), trim))
  # Exporting data to csv to see
  # Remove rows with NA in the first column
  df_trimmed <- df_trimmed[!is.na(df_trimmed[, 1]), ]
  # excluding some irrelevant columns
  # create a vector of numbers using c ()
  keywords <- c ("HYDEL", "SMALL HYDEL", "WAPDA HYDEL.", "TOTAL HYDEL.", "GENCO-I", "GENCO-II", "GENCO-III", "TOTAL GENCOS", "TOTAL (R.E)", "TOTAL IPPs THERMAL", "TOTAL THERMAL", "IMP.FROM K-ELECTRIC", "TOTAL GENERATION", "NPCC LOAD MNGMT.", "REG. LOAD MNGMT.", "TOTAL SYS.DEMAND", "EXP. TO K-ELECTRIC", "NTDC DEMAND.", "EXP. JMS-KDA-1", "EXP. JMS-KDA-1", "EXP. NKI-KDA-33", "EXP. NKI-BALDIA", "PRIVATE POWER", "TIME", "IPP's  HYDEL", "TOTAL IPPs  HYDEL", "IPPs FOSSIL FUEL", "TOTAL IPPs FOSSIL FUEL", "TIME (FOR CALCULATION)", "IPP'S  BAGASSE", "TOTAL BAGASSE", "TIME (FOR CALCULATION)", "IPP'S  NUCLEAR", "TOTAL NUCLEAR", "TOTAL IPPs THERMAL.", "RENEWABLE  ENERGY", "SOLAR POWER", "TOTAL SOLAR", "WIND POWER", "TOTAL WINDS", "TOTAL (RENEWABLE  ENERGY)", "TIME (FOR CALCULATION)", "IPPs (ALL TYPES)", "NET EXPORT TO KESC.", "EXPORT+KESC")
  
  # removing columns that are in keyword list
  df_updated <- df_trimmed %>% filter(!HYDEL. %in% keywords)
  # Change the name of the first column
  colnames(df_updated)[1] <- "name"
  # making names similar with given file
  # each space and hyphen will become period
  # Replace spaces and hyphens with periods, ignoring leading and trailing spaces
  df_updated$name <- gsub(" ", ".", df_updated$name)  # Replace spaces with periods
  df_updated$name <- gsub("-", ".", df_updated$name)      # Replace hyphens with periods
  df_updated$name <- gsub("\\(|\\)", ".", df_updated$name)      # Replace small brackets ( or ) with periods

  
  # renaming Neelam to Neelum, to make it consistent
  if ("NEELAM.JEHLAM" %in% df_updated$name) {
  df_updated$name <- ifelse(df_updated$name == "NEELAM.JEHLAM", "NEELUM.JEHLUM", df_updated$name)
  }

  
  # reshaping data of csv, as desired by supervisor
  # Create a new data frame for the transformed data
  transformed_df <- data.frame(Time = character(),
                               Name = character(),
                               Energy_MWh = numeric(),
                               stringsAsFactors = FALSE)
  
  # Loop through each hour from 1 to 24
  for (hour in 1:24) {
    # Get the column name for the hour
    col_name <- sprintf("%02d00", hour)
    
    # Extract the data for the current hour
    hour_data <- df_updated[c("name", col_name)]
    
    # Rename the columns
    colnames(hour_data) <- c("Name", "Energy_MWh")
    
    # Add the time column
    hour_data$Time <- sprintf("%02d:00", hour)
    
    # Append the hour's data to the transformed dataframe
    transformed_df <- rbind(transformed_df, hour_data)
  }
  
  # Reorder the columns
  transformed_df <- transformed_df[, c("Time", "Name", "Energy_MWh")]
  # making 24:00 to 00:00
  # Create a new data frame for the transformed data
  transformed_df <- data.frame(Time = character(),
                               Name = character(),
                               Energy_MWh = numeric(),
                               stringsAsFactors = FALSE)
  
  # Loop through each hour from 1 to 24
  for (hour in 1:24) {
    # Get the column name for the hour
    col_name <- sprintf("%02d00", hour)
    
    # Extract the data for the current hour
    hour_data <- df_updated[c("name", col_name)]
    
    # Rename the columns
    colnames(hour_data) <- c("Name", "Energy_MWh")
    
    # Add the time column
    hour_data$Time <- sprintf("%02d:00", hour)
    
    # Append the hour's data to the transformed data frame
    transformed_df <- rbind(transformed_df, hour_data)
  }
  
  # Modify the time format for 2400 to 0000
  transformed_df$Time[transformed_df$Time == "24:00"] <- "00:00"
  
  # Reorder the columns
  transformed_df <- transformed_df[, c("Time", "Name", "Energy_MWh")]
  # making time 00:00 to appear in start
  # Create a temporary data frame to store records with time "00:00"
  temp_df <- transformed_df[transformed_df$Time == "00:00", ]
  
  # Remove records with time "00:00" from transformed_df
  transformed_df <- transformed_df[transformed_df$Time != "00:00", ]
  
  # Append the temporary data frame to transformed_df
  transformed_df <- rbind(temp_df, transformed_df)
  # Append file_date to the Time column in transformed_df
  transformed_df$Time <- paste(file_date, transformed_df$Time, sep = " ")
  # saving each data frame to global data frame to have collective data
  # Append transformed_df to global_df
  global_df <- rbind(global_df, transformed_df)
  # Update the global variable
  assign("global_df", global_df, envir = .GlobalEnv)
  # Save the updated transformed data frame to CSV
  # removing file extension = .xlsm from file names
  filename <- tools::file_path_sans_ext(filename)
  path <- "C:/Users/python/Documents/projR/processed_mw_sheets"
  write.csv(transformed_df, file.path(path, paste0(filename, ".csv")), row.names = FALSE, quote = FALSE)
  # write.csv(transformed_df, "transformed_data.csv", row.names = FALSE, quote = FALSE)
  
}


# Define the directory path
dir_path <- "C:/Users/python/Documents/projR/MAR-2022/"

# List all the files in the directory
files <- list.files(dir_path)

# Define a regular expression to match the date format
date_pattern <- "\\d{2} [A-Z]+ 2K\\d{2}"

# Define a date format to parse the date string
date_format <- "%d %B %Y"

# Create a list to store the newest file for each date
newest_files <- list()

# Loop through the files and filter by the extension and extract and transform the date
for (file in files) {
  # Skip temporary files starting with "~$"
  if (grepl("^~\\$", file)) {
    next
  }
  # Get the file name and extension
  name <- tools::file_path_sans_ext(file)
  ext <- tools::file_ext(file)
  
  # Check if the extension is xlsm
  if (ext == "xlsm") {
    # Search for the date pattern in the file name
    match <- str_match(name, date_pattern)
    if (!is.na(match)) {
      # If a match is found, parse the date string
      date <- match[1]
      # Remove any additional text within parentheses if present
      date <- str_remove(date, "\\(.*\\)")
      # Replace "2K" with "20" in the date string
      date <- str_replace(date, "2K", "20")
      date_obj <- parse_date_time(date, orders = date_format)
      
      # Format the date object as per the database format
      db_date <- paste(month(date_obj), day(date_obj), year(date_obj), sep = "/")
      
      # Check if the current file is newer than the previously stored file for the same date
      if (is.null(newest_files[[db_date]]) || 
          (is.numeric(file.mtime(file)) && 
           is.numeric(file.mtime(newest_files[[db_date]])) && 
           file.mtime(file) > file.mtime(newest_files[[db_date]]))) {
        newest_files[[db_date]] <- file
      }
    } else {
      # If no match is found, print an error message
      print(paste("No date found in", name))
    }
  }
}

# Print the newest files for each date
for (date in names(newest_files)) {
  process_mw_sheets(newest_files[[date]], date)
  # print(paste("processed", newest_files[[date]], sep = " "))
  # print(date)
  # print(newest_files[[date]])
}

# Save the collective global data frame to CSV
filename <- "collective_data"
path <- "C:/Users/python/Documents/projR/processed_mw_sheets"
write.csv(global_df, file.path(path, paste0(filename, ".csv")), row.names = FALSE, quote = FALSE)
# global_df$Time<-as.POSIXct(global_df$Time, tz="Asia/Karachi", format="%m/%d/%Y %H:%M")
# global_df$Month_Year <- format(global_df$Time, "%Y %b")


# Stop measuring time
end_time <- Sys.time()

# Calculate the elapsed time
elapsed_time <- end_time - start_time

# Print the elapsed time
print(elapsed_time)
```
<!-- copy of above cell -->
```{r}
# Function to extract a category based on start and end values
extract_peakhours <- function(file_name, filepath) {
# READING EXCEL FILE
  # filename<-"17 MARCH 2K22.xlsm"
  # # filename<-"02 MARCH 2K22.xlsm"
  # # Read the Excel file
  # file_path <-"C:/Users/python/Documents/projR/MAR-2022/"
  filename <- file_name
  file_path <- filepath

# Read the Excel file
df_peakhour <- read_excel(file.path(file_path, filename), sheet = "MW", range = "A2:AW311")

# Select columns A, Z1 to AW1
df_peakhourV2 <- df_peakhour %>% select(1, 26:49)
# Save the first row as "row1" and the second row as "row2"
row1 <- df_peakhourV2[1, ]
row2 <- df_peakhourV2[2, ]

# Print the saved rows
print(row1)
print(row2)
# combining using rbind row1 and row2
row_merged <- rbind(row1, row2)
head(row_merged)
# Assuming row_merged is your dataframe
row_merged <- row_merged %>% mutate(across(everything(), as.character))
# Assuming row_merged is your dataframe
row_merged[is.na(row_merged)] <- ""
# Assuming row_merged is your dataframe
new_header_final <- c("name", paste0("p", 1:9), "calc_enrg", "act_enrg", "diff_percentage", "a_load", "max_1", "min_1", "max_2", "min_2", "max_3", "min_3", "average", "energy_generation", "L_one_true_1", "L_two_false_90", "L_three_1")
# Assign the new header to the dataframe
colnames(row_merged) <- new_header_final

head(row_merged)
# Use row 2 as the new header
new_header <- df_peakhourV2[2, ]

# Remove the first two rows which were used for the header
df_peakhourV2 <- df_peakhourV2[-c(1, 2), ]
# # Merge row 1 and 2 and use it as the new header
# new_header <- paste(df_peakhourV2[1, ], df_peakhourV2[2, ], sep = "_")
# colnames(df_peakhourV2) <- new_header

# # Remove the first two rows which were merged
# df_peakhourV2 <- df_peakhourV2[-c(1, 2), ]
# create a vector of numbers using c ()
  keywords <- c ("HYDEL", "SMALL HYDEL", "WAPDA HYDEL.", "TOTAL HYDEL.", "GENCO-I", "GENCO-II", "GENCO-III", "TOTAL GENCOS", "TOTAL (R.E)", "TOTAL IPPs THERMAL", "TOTAL THERMAL", "IMP.FROM K-ELECTRIC", "TOTAL GENERATION", "NPCC LOAD MNGMT.", "REG. LOAD MNGMT.", "TOTAL SYS.DEMAND", "EXP. TO K-ELECTRIC", "NTDC DEMAND.", "EXP. JMS-KDA-1", "EXP. JMS-KDA-1", "EXP. NKI-KDA-33", "EXP. NKI-BALDIA", "PRIVATE POWER", "TIME", "IPP's  HYDEL", "TOTAL IPPs  HYDEL", "IPPs FOSSIL FUEL", "TOTAL IPPs FOSSIL FUEL", "TIME (FOR CALCULATION)", "IPP'S  BAGASSE", "TOTAL BAGASSE", "TIME (FOR CALCULATION)", "IPP'S  NUCLEAR", "TOTAL NUCLEAR", "TOTAL IPPs THERMAL.", "RENEWABLE  ENERGY", "SOLAR POWER", "TOTAL SOLAR", "WIND POWER", "TOTAL WINDS", "TOTAL (RENEWABLE  ENERGY)", "TIME (FOR CALCULATION)", "IPPs (ALL TYPES)", "NET EXPORT TO KESC.", "EXPORT+KESC")
  # Change the name of the first column
  colnames(df_peakhourV2)[1] <- "name"
  #remove rows containing FUT
  df_peakhourV2<-df_peakhourV2[-grep("FUT", df_peakhourV2$name), ]
  # before removing spaces
  # removing rows which are other than power plants
  trim <- function( x ) {
    gsub("(^[[:space:]]+|[[:space:]]+$)", "", x)
  }
  # removing leading & trailing spaces from all columns
  df_peakhourV2 <- df_peakhourV2 %>% mutate(across(everything(), trim))
  # Exporting data to csv to see
  # Remove rows with NA in the first column
  df_peakhourV2 <- df_peakhourV2[!is.na(df_peakhourV2[, 1]), ]
 # Remove rows where the value in the first column matches any of the keywords
  # removing columns that are in keyword list
  df_peakhourV2 <- df_peakhourV2 %>% filter(!name %in% keywords)
  
  # making names similar with given file
  # each space and hyphen will become period
  # Replace spaces and hyphens with periods, ignoring leading and trailing spaces
  df_peakhourV2$name <- gsub(" ", ".", df_peakhourV2$name)  # Replace spaces with periods
  df_peakhourV2$name <- gsub("-", ".", df_peakhourV2$name)      # Replace hyphens with periods
  df_peakhourV2$name <- gsub("\\(|\\)", ".", df_peakhourV2$name)      # Replace small brackets ( or ) with periods

  
  # renaming Neelam to Neelum, to make it consistent
  if ("NEELAM.JEHLAM" %in% df_peakhourV2$name) {
  df_peakhourV2$name <- ifelse(df_peakhourV2$name == "NEELAM.JEHLAM", "NEELUM.JEHLUM", df_peakhourV2$name)
  }
  # Assign the new header to the dataframe
  colnames(df_peakhourV2) <- new_header_final
  
  # Define the column names you want to convert to numeric
  numeric_columns <- c(paste0("p", 1:9), "calc_enrg", "act_enrg", "diff_percentage", "a_load", "max_1", "min_1", "max_2", "min_2", "max_3", "min_3", "average", "L_one_true_1", "L_two_false_90", "L_three_1")

  # changing types of columns, name and energy_generation will be character, remaining cols will be numeric
  df_peakhourV2 <- df_peakhourV2 %>%
    mutate(across(all_of(numeric_columns), as.numeric))
  return(df_peakhourV2)

}
# Function to extract a category based on start and end values
extract_category <- function(dataframe, start_value, end_value = NULL, category_name) {
  # Find the index of the starting point
  start_index <- which(dataframe$name == start_value)[1]
  
  if (is.null(end_value)) {
    # For Wind category, select rows from start_index onwards
    category_df <- dataframe[start_index:nrow(dataframe), ]
  } else {
    # Find the index of the ending point
    end_index <- which(dataframe$name == end_value)[1]
  
    # Select the rows between start_index and end_index (inclusive)
    category_df <- dataframe[start_index:end_index, ]
    # removing last row
    category_df <- head(category_df, -1)
  }
  
  # Add a category column
  category_df$category <- category_name
  
  return(category_df)
}
# combining categories 
combine_categories <- function(df_updated){
  # new code added
  MW_worksheet <- df_updated
  # Example usage
  Hydel <- extract_category(MW_worksheet, "TARBELA", "JAMSHORO", "Hydel")
  Genco1 <- extract_category(MW_worksheet, "JAMSHORO", "GUDDU...5.13", "Genco1")
  Genco2 <- extract_category(MW_worksheet, "GUDDU...5.13", "MUZAFFARGARH", "Genco2")
  Genco3 <- extract_category(MW_worksheet, "MUZAFFARGARH", "JAGRAN", "Genco3")
  IPPs_Hydel <- extract_category(MW_worksheet, "JAGRAN", "KAPCO", "IPPs Hydel")
  IPPs_Fossil_Fuel <- extract_category(MW_worksheet, "KAPCO", "JDW.II..SADIQ.ABAD.", "IPPs Fossil Fuel")
  IPPs_Bagasse <- extract_category(MW_worksheet, "JDW.II..SADIQ.ABAD.", "CHASHNUPP...I", "IPPs Bagasse")
  IPPs_Nuclear <- extract_category(MW_worksheet, "CHASHNUPP...I", "QUAID.AZAM.SOLAR", "IPPs Nuclear")
  Solar <- extract_category(MW_worksheet, "QUAID.AZAM.SOLAR", "FFCEL.WIND", "Solar")
  # wind category has no end point
  Wind <- extract_category(MW_worksheet, "FFCEL.WIND", category_name = "Wind")
  
  # Combine all the category dataframes into one
  MW_worksheet_with_categories <- rbind(Hydel, Genco1, Genco2, Genco3, IPPs_Hydel, IPPs_Fossil_Fuel, IPPs_Bagasse, IPPs_Nuclear, Solar, Wind)
  # Reorganize columns to place "category" just after "name", re-arranged category column from end to start (2nd column)
  MW_worksheet_with_categories <- MW_worksheet_with_categories %>%
    select(name, category, everything())
  # Convert numeric columns (excluding "name" and "category") to numeric type
  numeric_cols <- names(MW_worksheet_with_categories)[!(names(MW_worksheet_with_categories) %in% c("name", "category"))]
  MW_worksheet_with_categories <- MW_worksheet_with_categories %>%
    mutate(across(all_of(numeric_cols), as.numeric))
  # Round off numeric columns to 2 decimal places without trailing zeros for whole numbers
  MW_worksheet_with_categories[numeric_cols] <- lapply(MW_worksheet_with_categories[numeric_cols], function(x) {
    ifelse(abs(x - round(x)) < 1e-6, round(x), round(x, 2))
  })
  # new code ended
  return(MW_worksheet_with_categories)
}
# adding sub categories by fuel type and re-arranging global_df
rearrange_and_add_subcategories <- function(global_df, sub_categories_df_path) {
  # Read the CSV file and assign its data to sub_categories_df
  sub_categories_df <- read.csv(sub_categories_df_path)

  # Change the data types of all columns to character type
  sub_categories_df[] <- lapply(sub_categories_df, as.character)

  # matching names of both dataframes and adding new column PLANT.TYPE.WITH.FUEL in global_df and respective values from sub_categories_df
  global_df$sub_categories_by_fuel <- sub_categories_df$PLANT.TYPE.WITH.FUEL[match(global_df$Name, sub_categories_df$name)]
  
  # rearranging columns (Time, Name, Energy_MWh, category, sub_categories_by_fuel)
  global_df <- global_df %>%
    select(Time, Name, Energy_MWh, category, sub_categories_by_fuel)
  
  return(global_df)
}


# Start measuring time
start_time <- Sys.time()

# Create an empty global data frame
global_df <- data.frame(Time = character(), Name = character(), category = character(), Energy_MWh = numeric())
# creating an empty global_peakhour_df data frame
# Create a new dataframe with the specified column names
global_peakhour_df <- data.frame(
  name = character(),
  p1 = numeric(),
  p2 = numeric(),
  p3 = numeric(),
  p4 = numeric(),
  p5 = numeric(),
  p6 = numeric(),
  p7 = numeric(),
  p8 = numeric(),
  p9 = numeric(),
  calc_enrg = numeric(),
  act_enrg = numeric(),
  diff_percentage = numeric(),
  a_load = numeric(),
  max_1 = numeric(),
  min_1 = numeric(),
  max_2 = numeric(),
  min_2 = numeric(),
  max_3 = numeric(),
  min_3 = numeric(),
  average = numeric(),
  energy_generation = character(),
  L_one_true_1 = numeric(),
  L_two_false_90 = numeric(),
  L_three_1 = numeric()
)
df_modified <- data.frame()

process_mw_sheets <- function(fetched_file_name, fetched_date) {
  # READING EXCEL FILE
  file_date<-fetched_date
  filename<-fetched_file_name
  # filename<-"02 MARCH 2K22.xlsm"
  # Read the Excel file
  file_path <-"C:/Users/python/Documents/projR/MAR-2022/"
  df <- read_excel(file.path(file_path, filename), sheet = "MW", range = "A4:Y311")
  # df <- read_excel(filename, sheet = "MW", range = "A4:Y311")
  # Applying Basic Cleaning
  #remove rows containing FUT
  df<-df[-grep("FUT", df$HYDEL.), ]
  # before removing spaces
  #count the number of characters in the first column before trimming
  nchar(df$HYDEL.)
  # removing rows which are other than power plants
  trim <- function( x ) {
    gsub("(^[[:space:]]+|[[:space:]]+$)", "", x)
  }
  # removing leading & trailing spaces from all columns
  df_trimmed <- df %>% mutate(across(everything(), trim))
  # Exporting data to csv to see
  # Remove rows with NA in the first column
  df_trimmed <- df_trimmed[!is.na(df_trimmed[, 1]), ]
  # excluding some irrelevant columns
  # create a vector of numbers using c ()
  keywords <- c ("HYDEL", "SMALL HYDEL", "WAPDA HYDEL.", "TOTAL HYDEL.", "GENCO-I", "GENCO-II", "GENCO-III", "TOTAL GENCOS", "TOTAL (R.E)", "TOTAL IPPs THERMAL", "TOTAL THERMAL", "IMP.FROM K-ELECTRIC", "TOTAL GENERATION", "NPCC LOAD MNGMT.", "REG. LOAD MNGMT.", "TOTAL SYS.DEMAND", "EXP. TO K-ELECTRIC", "NTDC DEMAND.", "EXP. JMS-KDA-1", "EXP. JMS-KDA-1", "EXP. NKI-KDA-33", "EXP. NKI-BALDIA", "PRIVATE POWER", "TIME", "IPP's  HYDEL", "TOTAL IPPs  HYDEL", "IPPs FOSSIL FUEL", "TOTAL IPPs FOSSIL FUEL", "TIME (FOR CALCULATION)", "IPP'S  BAGASSE", "TOTAL BAGASSE", "TIME (FOR CALCULATION)", "IPP'S  NUCLEAR", "TOTAL NUCLEAR", "TOTAL IPPs THERMAL.", "RENEWABLE  ENERGY", "SOLAR POWER", "TOTAL SOLAR", "WIND POWER", "TOTAL WINDS", "TOTAL (RENEWABLE  ENERGY)", "TIME (FOR CALCULATION)", "IPPs (ALL TYPES)", "NET EXPORT TO KESC.", "EXPORT+KESC")
  
  # removing columns that are in keyword list
  df_updated <- df_trimmed %>% filter(!HYDEL. %in% keywords)
  # Change the name of the first column
  colnames(df_updated)[1] <- "name"
  # making names similar with given file
  # each space and hyphen will become period
  # Replace spaces and hyphens with periods, ignoring leading and trailing spaces
  df_updated$name <- gsub(" ", ".", df_updated$name)  # Replace spaces with periods
  df_updated$name <- gsub("-", ".", df_updated$name)      # Replace hyphens with periods
  df_updated$name <- gsub("\\(|\\)", ".", df_updated$name)      # Replace small brackets ( or ) with periods

  
  # renaming Neelam to Neelum, to make it consistent
  if ("NEELAM.JEHLAM" %in% df_updated$name) {
  df_updated$name <- ifelse(df_updated$name == "NEELAM.JEHLAM", "NEELUM.JEHLUM", df_updated$name)
  }
  df_updated <- combine_categories(df_updated)
  
  # reshaping data of csv, as desired by supervisor
  # Create a new data frame for the transformed data
  # Create a new data frame for the transformed data
  transformed_df <- data.frame(Time = character(),
                               Name = character(),
                               Category = character(),
                               Energy_MWh = numeric(),
                               stringsAsFactors = FALSE)
  
  # Loop through each hour from 1 to 24
  for (hour in 1:24) {
    col_name <- sprintf("%02d00", hour)
    
    # Extract the data for the current hour
    hour_data <- df_updated[c("name", "category", col_name)]
    
    # Rename the columns
    colnames(hour_data) <- c("Name", "category", "Energy_MWh")
    
    # Add the time column
    hour_data$Time <- sprintf("%02d:00", hour)
    
    # Append the hour's data to the transformed data frame
    transformed_df <- rbind(transformed_df, hour_data)
  }
  
  
  
  
  # # Reorder the columns
  # transformed_df <- transformed_df[, c("Time", "Name", "category", "Energy_MWh")]
  # # making 24:00 to 00:00
  # # Create a new data frame for the transformed data
  # transformed_df <- data.frame(Time = character(),
  #                              Name = character(),
  #                              Category = character(),
  #                              Energy_MWh = numeric(),
  #                              stringsAsFactors = FALSE)
  # 
  # # Loop through each hour from 1 to 24
  # for (hour in 1:24) {
  #   # Get the column name for the hour
  #   col_name <- sprintf("%02d00", hour)
  #   
  #   # Extract the data for the current hour
  #   hour_data <- df_updated[c("name", "category", col_name)]
  #   
  #   # Rename the columns
  #   colnames(hour_data) <- c("Name", "category", "Energy_MWh")
  #   
  #   # Add the time column
  #   hour_data$Time <- sprintf("%02d:00", hour)
  #   
  #   # Append the hour's data to the transformed data frame
  #   transformed_df <- rbind(transformed_df, hour_data)
  # }
  
  
  
  # Modify the time format for 2400 to 0000
  transformed_df$Time[transformed_df$Time == "24:00"] <- "00:00"
  
  # Reorder the columns
  transformed_df <- transformed_df[, c("Time", "Name", "category", "Energy_MWh")]
  # making time 00:00 to appear in start
  # Create a temporary data frame to store records with time "00:00"
  temp_df <- transformed_df[transformed_df$Time == "00:00", ]
  
  # Remove records with time "00:00" from transformed_df
  transformed_df <- transformed_df[transformed_df$Time != "00:00", ]
  
  # Append the temporary data frame to transformed_df
  transformed_df <- rbind(temp_df, transformed_df)
  
  # Append file_date to the Time column in transformed_df
  transformed_df$Time <- paste(file_date, transformed_df$Time, sep = " ")
  # saving each data frame to global data frame to have collective data
  # Append transformed_df to global_df
  global_df <- rbind(global_df, transformed_df)
  # Update the global variable
  assign("global_df", global_df, envir = .GlobalEnv)
  # extracting peakhours data, and I will combine it at the end using match function
  local_peakhour_df <- extract_peakhours(filename, file_path)
  # Append local_peakhour_df to global_peakhour_df
  global_peakhour_df <- rbind(global_peakhour_df, local_peakhour_df)
  # Update the global variable
  assign("global_peakhour_df", global_peakhour_df, envir = .GlobalEnv)
  
  # Save the updated transformed data frame to CSV
  # removing file extension = .xlsm from file names
  filename <- tools::file_path_sans_ext(filename)
  path <- "C:/Users/python/Documents/projR/processed_mw_sheets"
  write.csv(transformed_df, file.path(path, paste0(filename, ".csv")), row.names = FALSE, quote = FALSE)
  # write.csv(transformed_df, "transformed_data.csv", row.names = FALSE, quote = FALSE)
  df_modified <- transformed_df
  
}


# Define the directory path
dir_path <- "C:/Users/python/Documents/projR/MAR-2022/"

# List all the files in the directory
files <- list.files(dir_path)

# Define a regular expression to match the date format
date_pattern <- "\\d{2} [A-Z]+ 2K\\d{2}"

# Define a date format to parse the date string
date_format <- "%d %B %Y"

# Create a list to store the newest file for each date
newest_files <- list()

# Loop through the files and filter by the extension and extract and transform the date
for (file in files) {
  # Skip temporary files starting with "~$"
  if (grepl("^~\\$", file)) {
    next
  }
  # Get the file name and extension
  name <- tools::file_path_sans_ext(file)
  ext <- tools::file_ext(file)
  
  # Check if the extension is xlsm
  if (ext == "xlsm") {
    # Search for the date pattern in the file name
    match <- str_match(name, date_pattern)
    if (!is.na(match)) {
      # If a match is found, parse the date string
      date <- match[1]
      # Remove any additional text within parentheses if present
      date <- str_remove(date, "\\(.*\\)")
      # Replace "2K" with "20" in the date string
      date <- str_replace(date, "2K", "20")
      date_obj <- parse_date_time(date, orders = date_format)
      
      # Format the date object as per the database format
      db_date <- paste(month(date_obj), day(date_obj), year(date_obj), sep = "/")
      
      # Check if the current file is newer than the previously stored file for the same date
      if (is.null(newest_files[[db_date]]) || 
          (is.numeric(file.mtime(file)) && 
           is.numeric(file.mtime(newest_files[[db_date]])) && 
           file.mtime(file) > file.mtime(newest_files[[db_date]]))) {
        newest_files[[db_date]] <- file
      }
    } else {
      # If no match is found, print an error message
      print(paste("No date found in", name))
    }
  }
}

# Print the newest files for each date
for (date in names(newest_files)) {
  process_mw_sheets(newest_files[[date]], date)
  # print(paste("processed", newest_files[[date]], sep = " "))
  # print(date)
  # print(newest_files[[date]])
}
# Assuming global_df and sub_categories_df_path are provided
global_df <- rearrange_and_add_subcategories(global_df, "C:/Users/python/Documents/projR/Power Plants Type.csv")
# Save the collective global data frame to CSV
filename <- "collective_data"
path <- "C:/Users/python/Documents/projR/processed_mw_sheets"
write.csv(global_df, file.path(path, paste0(filename, ".csv")), row.names = FALSE, quote = FALSE)
# global_df$Time<-as.POSIXct(global_df$Time, tz="Asia/Karachi", format="%m/%d/%Y %H:%M")
# global_df$Month_Year <- format(global_df$Time, "%Y %b")


# Stop measuring time
end_time <- Sys.time()

# Calculate the elapsed time
elapsed_time <- end_time - start_time

# Print the elapsed time
print(elapsed_time)
```
<!-- sub categories of powerplant merging based on powerplant names -->
```{r converted in function in above cell named rearrange_and_add_subcategories, eval=FALSE, include=FALSE}
# Read the CSV file and assign its data to sub_categories_df
sub_categories_df <- read.csv("C:/Users/python/Documents/projR/Power Plants Type.csv")

# Change the data types of all columns to character type
sub_categories_df[] <- lapply(sub_categories_df, as.character)

# Check if data exists in both dataframes
print("Global DataFrame:")
print(head(global_df))

print("Sub Categories DataFrame:")
head(sub_categories_df)
# Assuming global_df and sub_categories_df are your dataframes

# matching names of both dataframes and adding new column PLANT.TYPE.WITH.FUEL in global_df and respective values from sub_categories_df
global_df$sub_categories_by_fuel <- sub_categories_df$PLANT.TYPE.WITH.FUEL[match(global_df$Name, sub_categories_df$name)]
# rearranging columns (Time, Name, Energy_MWh, category, sub_categories_by_fuel)
global_df <- global_df %>%
  select(Time, Name, Energy_MWh, category, sub_categories_by_fuel)
# now making primary categories Hydro, Renewable, Nuclear, Thermal




```
# cleaning new data related to peak hours, mw worksheet
```{r}

# READING EXCEL FILE
  filename<-"17 MARCH 2K22.xlsm"
  # filename<-"02 MARCH 2K22.xlsm"
  # Read the Excel file
  file_path <-"C:/Users/python/Documents/projR/MAR-2022/"


# Read the Excel file
df_peakhour <- read_excel(file.path(file_path, filename), sheet = "MW", range = "A2:AW311")

# Select columns A, Z1 to AW1
df_peakhourV2 <- df_peakhour %>% select(1, 26:49)
# Save the first row as "row1" and the second row as "row2"
row1 <- df_peakhourV2[1, ]
row2 <- df_peakhourV2[2, ]

# Print the saved rows
print(row1)
print(row2)
# combining using rbind row1 and row2
row_merged <- rbind(row1, row2)
head(row_merged)
# Assuming row_merged is your dataframe
row_merged <- row_merged %>% mutate(across(everything(), as.character))
# Assuming row_merged is your dataframe
row_merged[is.na(row_merged)] <- ""
# Assuming row_merged is your dataframe
new_header_final <- c("name", paste0("p", 1:9), "calc_enrg", "act_enrg", "diff_percentage", "a_load", "max_1", "min_1", "max_2", "min_2", "max_3", "min_3", "average", "energy_generation", "L_one_true_1", "L_two_false_90", "L_three_1")
# Assign the new header to the dataframe
colnames(row_merged) <- new_header_final

head(row_merged)
# Use row 2 as the new header
new_header <- df_peakhourV2[2, ]

# Remove the first two rows which were used for the header
df_peakhourV2 <- df_peakhourV2[-c(1, 2), ]
# # Merge row 1 and 2 and use it as the new header
# new_header <- paste(df_peakhourV2[1, ], df_peakhourV2[2, ], sep = "_")
# colnames(df_peakhourV2) <- new_header

# # Remove the first two rows which were merged
# df_peakhourV2 <- df_peakhourV2[-c(1, 2), ]
# create a vector of numbers using c ()
  keywords <- c ("HYDEL", "SMALL HYDEL", "WAPDA HYDEL.", "TOTAL HYDEL.", "GENCO-I", "GENCO-II", "GENCO-III", "TOTAL GENCOS", "TOTAL (R.E)", "TOTAL IPPs THERMAL", "TOTAL THERMAL", "IMP.FROM K-ELECTRIC", "TOTAL GENERATION", "NPCC LOAD MNGMT.", "REG. LOAD MNGMT.", "TOTAL SYS.DEMAND", "EXP. TO K-ELECTRIC", "NTDC DEMAND.", "EXP. JMS-KDA-1", "EXP. JMS-KDA-1", "EXP. NKI-KDA-33", "EXP. NKI-BALDIA", "PRIVATE POWER", "TIME", "IPP's  HYDEL", "TOTAL IPPs  HYDEL", "IPPs FOSSIL FUEL", "TOTAL IPPs FOSSIL FUEL", "TIME (FOR CALCULATION)", "IPP'S  BAGASSE", "TOTAL BAGASSE", "TIME (FOR CALCULATION)", "IPP'S  NUCLEAR", "TOTAL NUCLEAR", "TOTAL IPPs THERMAL.", "RENEWABLE  ENERGY", "SOLAR POWER", "TOTAL SOLAR", "WIND POWER", "TOTAL WINDS", "TOTAL (RENEWABLE  ENERGY)", "TIME (FOR CALCULATION)", "IPPs (ALL TYPES)", "NET EXPORT TO KESC.", "EXPORT+KESC")
  # Change the name of the first column
  colnames(df_peakhourV2)[1] <- "name"
  #remove rows containing FUT
  df_peakhourV2<-df_peakhourV2[-grep("FUT", df_peakhourV2$name), ]
  # before removing spaces
  # removing rows which are other than power plants
  trim <- function( x ) {
    gsub("(^[[:space:]]+|[[:space:]]+$)", "", x)
  }
  # removing leading & trailing spaces from all columns
  df_peakhourV2 <- df_peakhourV2 %>% mutate(across(everything(), trim))
  # Exporting data to csv to see
  # Remove rows with NA in the first column
  df_peakhourV2 <- df_peakhourV2[!is.na(df_peakhourV2[, 1]), ]
 # Remove rows where the value in the first column matches any of the keywords
  # removing columns that are in keyword list
  df_peakhourV2 <- df_peakhourV2 %>% filter(!name %in% keywords)
  
  # making names similar with given file
  # each space and hyphen will become period
  # Replace spaces and hyphens with periods, ignoring leading and trailing spaces
  df_peakhourV2$name <- gsub(" ", ".", df_peakhourV2$name)  # Replace spaces with periods
  df_peakhourV2$name <- gsub("-", ".", df_peakhourV2$name)      # Replace hyphens with periods
  df_peakhourV2$name <- gsub("\\(|\\)", ".", df_peakhourV2$name)      # Replace small brackets ( or ) with periods

  
  # renaming Neelam to Neelum, to make it consistent
  if ("NEELAM.JEHLAM" %in% df_peakhourV2$name) {
  df_peakhourV2$name <- ifelse(df_peakhourV2$name == "NEELAM.JEHLAM", "NEELUM.JEHLUM", df_peakhourV2$name)
  }
  # Assign the new header to the dataframe
  colnames(df_peakhourV2) <- new_header_final
  
  # Define the column names you want to convert to numeric
  numeric_columns <- c(paste0("p", 1:9), "calc_enrg", "act_enrg", "diff_percentage", "a_load", "max_1", "min_1", "max_2", "min_2", "max_3", "min_3", "average", "L_one_true_1", "L_two_false_90", "L_three_1")

  # changing types of columns, name and energy_generation will be character, remaining cols will be numeric
  df_peakhourV2 <- df_peakhourV2 %>%
    mutate(across(all_of(numeric_columns), as.numeric))
  Time <- paste("2022-03-17",row_merged[2,2:10])
  Time= as.POSIXct(Time,format="%Y-%m-%d %H%M")
  
  # Extract the values from row 1 for max_1, max_2, and max_3
max_1_value <- row_merged[1, "max_1"]
max_2_value <- row_merged[1, "max_2"]
max_3_value <- row_merged[1, "max_3"]
# Update row 2 of row_merged DataFrame
# Update row 2 of row_merged DataFrame for max and min columns
max_min_columns <- c("max_1", "max_2", "max_3", "min_1", "min_2", "min_3")

# Define corresponding values for each set of columns
value_map <- c(max_1_value, max_1_value, max_2_value, max_2_value, max_3_value, max_3_value)

# Update row 2 of row_merged DataFrame for max and min columns
for (i in 1:length(max_min_columns)) {
  col_name <- max_min_columns[i]
  value <- value_map[i]
  row_merged[2, col_name] <- paste(value, row_merged[2, col_name], sep = " - ")
}
# Define the values for the last three columns
L_one_true_1_value <- "L_one_true_1"
L_two_false_90_value <- "L_two_false_90"
L_three_1_value <- "L_three_1"

# Update row 2 of row_merged DataFrame for each of the last three columns
row_merged[2, "L_one_true_1"] <- L_one_true_1_value
row_merged[2, "L_two_false_90"] <- L_two_false_90_value
row_merged[2, "L_three_1"] <- L_three_1_value

# the_date <- "2022-03-17"
# df_max_min <- df_peakhourV2[, c(1, 15:21)]
# # Create a new column "Time" with the same value for all rows
# df_max_min$Time <- as.POSIXct(the_date, format = "%Y-%m-%d")
# str(df_max_min)

# Select the first 10 columns of df_peakhourV2
df_peakhourV2 <- df_peakhourV2[, 1:10]


# Load the tidyr package if it's not already loaded
library(tidyr)


# Use pivot_longer to reshape the DataFrame
df_long <- df_peakhourV2 %>%
  pivot_longer(cols = starts_with("p"),
               names_to = "peak_no",
               values_to = "peak_values")

# Add the Time column by repeating the Time vector
df_long$Time <- rep(Time, length.out = nrow(df_long))
str(df_long)
```
# max_min hours from MW worksheet
```{r}
# READING EXCEL FILE
  filename<-"17 MARCH 2K22.xlsm"
  # filename<-"02 MARCH 2K22.xlsm"
  # Read the Excel file
  file_path <-"C:/Users/python/Documents/projR/MAR-2022/"


# Read the Excel file
df_peakhour <- read_excel(file.path(file_path, filename), sheet = "MW", range = "A2:AW311")

# Select columns A, Z1 to AW1
df_peakhourV2 <- df_peakhour %>% select(1, 26:49)
# Save the first row as "row1" and the second row as "row2"
row1 <- df_peakhourV2[1, ]
row2 <- df_peakhourV2[2, ]

# Print the saved rows
print(row1)
print(row2)
# combining using rbind row1 and row2
row_merged <- rbind(row1, row2)
head(row_merged)
# Assuming row_merged is your dataframe
row_merged <- row_merged %>% mutate(across(everything(), as.character))
# Assuming row_merged is your dataframe
row_merged[is.na(row_merged)] <- ""
# Assuming row_merged is your dataframe
new_header_final <- c("name", paste0("p", 1:9), "calc_enrg", "act_enrg", "diff_percentage", "a_load", "max_1", "min_1", "max_2", "min_2", "max_3", "min_3", "average", "energy_generation", "L_one_true_1", "L_two_false_90", "L_three_1")
# Assign the new header to the dataframe
colnames(row_merged) <- new_header_final

head(row_merged)
# Use row 2 as the new header
new_header <- df_peakhourV2[2, ]

# Remove the first two rows which were used for the header
df_peakhourV2 <- df_peakhourV2[-c(1, 2), ]
# # Merge row 1 and 2 and use it as the new header
# new_header <- paste(df_peakhourV2[1, ], df_peakhourV2[2, ], sep = "_")
# colnames(df_peakhourV2) <- new_header

# # Remove the first two rows which were merged
# df_peakhourV2 <- df_peakhourV2[-c(1, 2), ]
# create a vector of numbers using c ()
  keywords <- c ("HYDEL", "SMALL HYDEL", "WAPDA HYDEL.", "TOTAL HYDEL.", "GENCO-I", "GENCO-II", "GENCO-III", "TOTAL GENCOS", "TOTAL (R.E)", "TOTAL IPPs THERMAL", "TOTAL THERMAL", "IMP.FROM K-ELECTRIC", "TOTAL GENERATION", "NPCC LOAD MNGMT.", "REG. LOAD MNGMT.", "TOTAL SYS.DEMAND", "EXP. TO K-ELECTRIC", "NTDC DEMAND.", "EXP. JMS-KDA-1", "EXP. JMS-KDA-1", "EXP. NKI-KDA-33", "EXP. NKI-BALDIA", "PRIVATE POWER", "TIME", "IPP's  HYDEL", "TOTAL IPPs  HYDEL", "IPPs FOSSIL FUEL", "TOTAL IPPs FOSSIL FUEL", "TIME (FOR CALCULATION)", "IPP'S  BAGASSE", "TOTAL BAGASSE", "TIME (FOR CALCULATION)", "IPP'S  NUCLEAR", "TOTAL NUCLEAR", "TOTAL IPPs THERMAL.", "RENEWABLE  ENERGY", "SOLAR POWER", "TOTAL SOLAR", "WIND POWER", "TOTAL WINDS", "TOTAL (RENEWABLE  ENERGY)", "TIME (FOR CALCULATION)", "IPPs (ALL TYPES)", "NET EXPORT TO KESC.", "EXPORT+KESC")
  # Change the name of the first column
  colnames(df_peakhourV2)[1] <- "name"
  #remove rows containing FUT
  df_peakhourV2<-df_peakhourV2[-grep("FUT", df_peakhourV2$name), ]
  # before removing spaces
  # removing rows which are other than power plants
  trim <- function( x ) {
    gsub("(^[[:space:]]+|[[:space:]]+$)", "", x)
  }
  # removing leading & trailing spaces from all columns
  df_peakhourV2 <- df_peakhourV2 %>% mutate(across(everything(), trim))
  # Exporting data to csv to see
  # Remove rows with NA in the first column
  df_peakhourV2 <- df_peakhourV2[!is.na(df_peakhourV2[, 1]), ]
 # Remove rows where the value in the first column matches any of the keywords
  # removing columns that are in keyword list
  df_peakhourV2 <- df_peakhourV2 %>% filter(!name %in% keywords)
  
  # making names similar with given file
  # each space and hyphen will become period
  # Replace spaces and hyphens with periods, ignoring leading and trailing spaces
  df_peakhourV2$name <- gsub(" ", ".", df_peakhourV2$name)  # Replace spaces with periods
  df_peakhourV2$name <- gsub("-", ".", df_peakhourV2$name)      # Replace hyphens with periods
  df_peakhourV2$name <- gsub("\\(|\\)", ".", df_peakhourV2$name)      # Replace small brackets ( or ) with periods

  
  # renaming Neelam to Neelum, to make it consistent
  if ("NEELAM.JEHLAM" %in% df_peakhourV2$name) {
  df_peakhourV2$name <- ifelse(df_peakhourV2$name == "NEELAM.JEHLAM", "NEELUM.JEHLUM", df_peakhourV2$name)
  }
  # Assign the new header to the dataframe
  colnames(df_peakhourV2) <- new_header_final
  
  # Define the column names you want to convert to numeric
  numeric_columns <- c(paste0("p", 1:9), "calc_enrg", "act_enrg", "diff_percentage", "a_load", "max_1", "min_1", "max_2", "min_2", "max_3", "min_3", "average", "L_one_true_1", "L_two_false_90", "L_three_1")

  # changing types of columns, name and energy_generation will be character, remaining cols will be numeric
  df_peakhourV2 <- df_peakhourV2 %>%
    mutate(across(all_of(numeric_columns), as.numeric))
  Time <- paste("2022-03-17",row_merged[2,2:10])
  Time= as.POSIXct(Time,format="%Y-%m-%d %H%M")
  
  # Extract the values from row 1 for max_1, max_2, and max_3
max_1_value <- row_merged[1, "max_1"]
max_2_value <- row_merged[1, "max_2"]
max_3_value <- row_merged[1, "max_3"]
# Update row 2 of row_merged DataFrame
# Update row 2 of row_merged DataFrame for max and min columns
max_min_columns <- c("max_1", "max_2", "max_3", "min_1", "min_2", "min_3")

# Define corresponding values for each set of columns
value_map <- c(max_1_value, max_1_value, max_2_value, max_2_value, max_3_value, max_3_value)

# Update row 2 of row_merged DataFrame for max and min columns
for (i in 1:length(max_min_columns)) {
  col_name <- max_min_columns[i]
  value <- value_map[i]
  row_merged[2, col_name] <- paste(value, row_merged[2, col_name], sep = " - ")
}
# Define the values for the last three columns
L_one_true_1_value <- "L_one_true_1"
L_two_false_90_value <- "L_two_false_90"
L_three_1_value <- "L_three_1"

# Update row 2 of row_merged DataFrame for each of the last three columns
row_merged[2, "L_one_true_1"] <- L_one_true_1_value
row_merged[2, "L_two_false_90"] <- L_two_false_90_value
row_merged[2, "L_three_1"] <- L_three_1_value

file_date <- "03/17/2022"
# Convert file_date to Date format
file_date <- as.Date(file_date, format = "%m/%d/%Y")
  
# Format the date as "yyyy-mm-dd"
formatted_date <- format(file_date, format = "%Y-%m-%d")
df_max_min <- df_peakhourV2[, c(1, 15:21)]
# Create a new column "Time" with the same value for all rows
df_max_min$Time <- as.POSIXct(formatted_date, format = "%Y-%m-%d")



# # Assuming df_max_min is your DataFrame
# # Get the names of columns 2 and 3
# column_2_name <- names(df_max_min)[2]
# column_3_name <- names(df_max_min)[3]
# column_4_name <- names(df_max_min)[4]
# column_5_name <- names(df_max_min)[5]
# column_6_name <- names(df_max_min)[6]
# column_7_name <- names(df_max_min)[7]
# # column average
# column_8_name <- names(df_max_min)[8]
# 
# # Rename columns with prefixes based on the variables
# names(df_max_min)[2] <- paste(max_1_value, column_2_name, sep = "_")
# names(df_max_min)[3] <- paste(max_1_value, column_3_name, sep = "_")
# names(df_max_min)[4] <- paste(max_2_value, column_4_name, sep = "_")
# names(df_max_min)[5] <- paste(max_2_value, column_5_name, sep = "_")
# names(df_max_min)[6] <- paste(max_3_value, column_6_name, sep = "_")
# names(df_max_min)[7] <- paste(max_3_value, column_7_name, sep = "_")
# names(df_max_min)[8] <- paste(max_1_value, column_8_name, sep = "_")

# Reorder the columns
# # Now, df_max_min will have the "Time" column as the first column
# df_max_min <- df_max_min %>%
#   select(Time, everything())

# Add three new columns with the same values for all rows
df_max_min$time_range_one <- max_1_value$max_1
df_max_min$time_range_two <- max_2_value$max_2
df_max_min$time_range_three <- max_3_value$max_3
# Define the desired order of column names
desired_order <- c("Time", "name", "time_range_one", "max_1", "min_1", "average", "time_range_two", "max_2", "min_2", "time_range_three", "max_3", "min_3")

# Reorder the columns according to the desired order
df_max_min <- df_max_min %>%
  select(desired_order)
str(df_max_min)



extract_max_min_avg <- function(file_name, file_path, file_date) {
  # Convert file_date to Date format
  file_date <- as.Date(file_date, format = "%m/%d/%Y")
  
  # Format the date as "yyyy-mm-dd"
  formatted_date <- format(file_date, format = "%Y-%m-%d")
  # Construct the full file path
  full_file_path <- file.path(file_path, file_name)
  
  # Read the Excel file
  df_peakhour <- read_excel(full_file_path, sheet = "MW", range = "A2:AW311")
  
  # Select columns A, Z1 to AW1
  df_peakhourV2 <- df_peakhour %>% select(1, 26:49)
  # Save the first row as "row1" and the second row as "row2"
  row1 <- df_peakhourV2[1, ]
  row2 <- df_peakhourV2[2, ]
  
  # Print the saved rows
  print(row1)
  print(row2)
  # combining using rbind row1 and row2
  row_merged <- rbind(row1, row2)
  head(row_merged)
  # Assuming row_merged is your dataframe
  row_merged <- row_merged %>% mutate(across(everything(), as.character))
  # Assuming row_merged is your dataframe
  row_merged[is.na(row_merged)] <- ""
  # Assuming row_merged is your dataframe
  new_header_final <- c("name", paste0("p", 1:9), "calc_enrg", "act_enrg", "diff_percentage", "a_load", "max_1", "min_1", "max_2", "min_2", "max_3", "min_3", "average", "energy_generation", "L_one_true_1", "L_two_false_90", "L_three_1")
  # Assign the new header to the dataframe
  colnames(row_merged) <- new_header_final
  
  head(row_merged)
  # Use row 2 as the new header
  new_header <- df_peakhourV2[2, ]
  
  # Remove the first two rows which were used for the header
  df_peakhourV2 <- df_peakhourV2[-c(1, 2), ]
  # # Merge row 1 and 2 and use it as the new header
  # new_header <- paste(df_peakhourV2[1, ], df_peakhourV2[2, ], sep = "_")
  # colnames(df_peakhourV2) <- new_header
  
  # # Remove the first two rows which were merged
  # df_peakhourV2 <- df_peakhourV2[-c(1, 2), ]
  # create a vector of numbers using c ()
  keywords <- c ("HYDEL", "SMALL HYDEL", "WAPDA HYDEL.", "TOTAL HYDEL.", "GENCO-I", "GENCO-II", "GENCO-III", "TOTAL GENCOS", "TOTAL (R.E)", "TOTAL IPPs THERMAL", "TOTAL THERMAL", "IMP.FROM K-ELECTRIC", "TOTAL GENERATION", "NPCC LOAD MNGMT.", "REG. LOAD MNGMT.", "TOTAL SYS.DEMAND", "EXP. TO K-ELECTRIC", "NTDC DEMAND.", "EXP. JMS-KDA-1", "EXP. JMS-KDA-1", "EXP. NKI-KDA-33", "EXP. NKI-BALDIA", "PRIVATE POWER", "TIME", "IPP's  HYDEL", "TOTAL IPPs  HYDEL", "IPPs FOSSIL FUEL", "TOTAL IPPs FOSSIL FUEL", "TIME (FOR CALCULATION)", "IPP'S  BAGASSE", "TOTAL BAGASSE", "TIME (FOR CALCULATION)", "IPP'S  NUCLEAR", "TOTAL NUCLEAR", "TOTAL IPPs THERMAL.", "RENEWABLE  ENERGY", "SOLAR POWER", "TOTAL SOLAR", "WIND POWER", "TOTAL WINDS", "TOTAL (RENEWABLE  ENERGY)", "TIME (FOR CALCULATION)", "IPPs (ALL TYPES)", "NET EXPORT TO KESC.", "EXPORT+KESC")
  # Change the name of the first column
  colnames(df_peakhourV2)[1] <- "name"
  #remove rows containing FUT
  df_peakhourV2<-df_peakhourV2[-grep("FUT", df_peakhourV2$name), ]
  # before removing spaces
  # removing rows which are other than power plants
  trim <- function( x ) {
    gsub("(^[[:space:]]+|[[:space:]]+$)", "", x)
  }
  # removing leading & trailing spaces from all columns
  df_peakhourV2 <- df_peakhourV2 %>% mutate(across(everything(), trim))
  # Exporting data to csv to see
  # Remove rows with NA in the first column
  df_peakhourV2 <- df_peakhourV2[!is.na(df_peakhourV2[, 1]), ]
  # Remove rows where the value in the first column matches any of the keywords
  # removing columns that are in keyword list
  df_peakhourV2 <- df_peakhourV2 %>% filter(!name %in% keywords)
  
  # making names similar with given file
  # each space and hyphen will become period
  # Replace spaces and hyphens with periods, ignoring leading and trailing spaces
  df_peakhourV2$name <- gsub(" ", ".", df_peakhourV2$name)  # Replace spaces with periods
  df_peakhourV2$name <- gsub("-", ".", df_peakhourV2$name)      # Replace hyphens with periods
  df_peakhourV2$name <- gsub("\\(|\\)", ".", df_peakhourV2$name)      # Replace small brackets ( or ) with periods
  
  
  # renaming Neelam to Neelum, to make it consistent
  if ("NEELAM.JEHLAM" %in% df_peakhourV2$name) {
    df_peakhourV2$name <- ifelse(df_peakhourV2$name == "NEELAM.JEHLAM", "NEELUM.JEHLUM", df_peakhourV2$name)
  }
  # Assign the new header to the dataframe
  colnames(df_peakhourV2) <- new_header_final
  
  # Define the column names you want to convert to numeric
  numeric_columns <- c(paste0("p", 1:9), "calc_enrg", "act_enrg", "diff_percentage", "a_load", "max_1", "min_1", "max_2", "min_2", "max_3", "min_3", "average", "L_one_true_1", "L_two_false_90", "L_three_1")
  
  # changing types of columns, name and energy_generation will be character, remaining cols will be numeric
  df_peakhourV2 <- df_peakhourV2 %>%
    mutate(across(all_of(numeric_columns), as.numeric))
  Time <- paste("2022-03-17",row_merged[2,2:10])
  Time= as.POSIXct(Time,format="%Y-%m-%d %H%M")
  
  # Extract the values from row 1 for max_1, max_2, and max_3
  max_1_value <- row_merged[1, "max_1"]
  max_2_value <- row_merged[1, "max_2"]
  max_3_value <- row_merged[1, "max_3"]
  # Update row 2 of row_merged DataFrame
  # Update row 2 of row_merged DataFrame for max and min columns
  max_min_columns <- c("max_1", "max_2", "max_3", "min_1", "min_2", "min_3")
  
  # Define corresponding values for each set of columns
  value_map <- c(max_1_value, max_1_value, max_2_value, max_2_value, max_3_value, max_3_value)
  
  # Update row 2 of row_merged DataFrame for max and min columns
  for (i in 1:length(max_min_columns)) {
    col_name <- max_min_columns[i]
    value <- value_map[i]
    row_merged[2, col_name] <- paste(value, row_merged[2, col_name], sep = " - ")
  }
  # Define the values for the last three columns
  L_one_true_1_value <- "L_one_true_1"
  L_two_false_90_value <- "L_two_false_90"
  L_three_1_value <- "L_three_1"
  
  # Update row 2 of row_merged DataFrame for each of the last three columns
  row_merged[2, "L_one_true_1"] <- L_one_true_1_value
  row_merged[2, "L_two_false_90"] <- L_two_false_90_value
  row_merged[2, "L_three_1"] <- L_three_1_value
  
  
  df_max_min <- df_peakhourV2[, c(1, 15:21)]
  # Create a new column "Time" with the same value for all rows
  df_max_min$Time <- as.POSIXct(formatted_date, format = "%Y-%m-%d")
  
  # Add three new columns with the same values for all rows
  df_max_min$time_range_one <- max_1_value$max_1
  df_max_min$time_range_two <- max_2_value$max_2
  df_max_min$time_range_three <- max_3_value$max_3
  # Define the desired order of column names
  desired_order <- c("Time", "name", "time_range_one", "max_1", "min_1", "average", "time_range_two", "max_2", "min_2", "time_range_three", "max_3", "min_3")
  
  # Reorder the columns according to the desired order
  df_max_min <- df_max_min %>%
    select(desired_order)
  return(df_max_min)
}
file_name <- "17 MARCH 2K22.xlsm"
file_path <- "C:/Users/python/Documents/projR/MAR-2022/"
file_date <- "03/17/2022"
df_returned <- extract_max_min_avg(file_name, file_path, file_date)

# Now, df_max_min will have "max_1_value" prefixed with values from columns 2 and 3

```

# GLOBAL DF BEFORE TRANSFORMING
```{r}
df_updated$name
```

# renaming column Name to name
```{r}
# Rename the column
colnames(global_df)[colnames(global_df) == "Name"] <- "name"

```
# reading demo file
```{r}
# Specify the path to your Excel file
excel_file <- "Hourly_Energy_MWh_Demo_Output_File.xlsx"

# Read the Excel file into a data frame
demo_df <- read_excel(excel_file)
# demo_df$Time<-format(demo_df$Time,"%Y-%m-%d %H:%M")
demo_df$Time<-as.POSIXct(demo_df$Time, tz="Asia/Karachi", format="%Y-%m-%d %H:%M")
#attr(demo_df$Time, "tzone") = "Asia/Karachi"
# demo_df$Time<-as.character(demo_df$Time)
#
```

#adustments
```{r}
global_df$Time<-as.POSIXct(global_df$Time, tz="Asia/Karachi", format="%m/%d/%Y %H:%M")
# global_df$Month_Year <- format(global_df$Time, "%Y %b")
```


# change data type to number, column=Energy_MWh, for both dataframes global_df & demo_df
```{r}
global_df$Energy_MWh <- as.numeric(global_df$Energy_MWh)
demo_df$Energy_MWh <- as.numeric(demo_df$Energy_MWh)
```
# row bind of global_df with demo_df (its the main/base/parent df)
```{r}
# Row bind global_df to demo_df
merged_df <- bind_rows(demo_df, global_df)
```
# merged_df unique names
```{r}
# unique(demo_df$name)
unique_names <- unique(merged_df$name)
arranged_names <- unique_names[order(substr(unique_names, 1, 1))]
arranged_names
```

# sorting merged_df
```{r}
# Sort merged_df based on Time column in descending order
sorted_df <- merged_df %>% arrange(Time)
# Sort global_df based on Time column in descending order
global_df <- global_df %>% arrange(Time)

```
# write merge_df to csv file
```{r}
# Save the merged_df data frame as a CSV file
write.csv(sorted_df, file = "Preprocessed_Hourly_Energy_MWh_DLR_File_FiscalYear2021-2022.csv", row.names = FALSE)

```
# REMOVING DUPLICATIONS, SIMILAR POWERPLANTS
```{r eval=FALSE, include=FALSE}
# ONLY FOUND NEELUM.JEHLUM $ NEELAM.JEHLAM
library(stringdist)

# Filter out unique names
unique_names <- unique(global_df$name)

# Create an empty data frame to store the results
similar_names_df <- data.frame(name1 = character(), name2 = character(), string_distance = numeric())

# Perform fuzzy matching for each unique name
for (name in unique_names) {
  matches <- amatch(name, global_df$name, maxDist = 10)
  similar_names <- data.frame(name1 = name, name2 = global_df$name[matches], string_distance = stringdist(name, global_df$name[matches], method = "lv"))
  similar_names_df <- rbind(similar_names_df, similar_names)
}

# Remove exact matches and duplicates
similar_names_df <- similar_names_df[similar_names_df$string_distance > 0, ]
similar_names_df <- unique(similar_names_df)

# Print the resulting data frame
print(similar_names_df)


```

```{r}
unique_names_demo <- unique(sorted_df$name)
arranged_names_demo <- unique_names_demo[order(substr(unique_names_demo, 1, 1))]
arranged_names_demo
```
```{r}
unique_names_sorted_df <- unique(sorted_df$name)
arranged_names_sorted_df <- unique_names_sorted_df[order(substr(unique_names_sorted_df, 1, 1))]
arranged_names_sorted_df
```
# cross matching names of both dataframes, mine and supervisor's
```{r}
matched_names <- arranged_names_sorted_df[arranged_names_sorted_df %in% arranged_names_demo]
matched_names
```

# making same number of powerplants in both global_df$name, as in demo_df$name
```{r eval=FALSE, include=FALSE}
# Step 1: Get unique power plant names from demo_df and sorted_df
demo_names <- unique(demo_df$name)
sorted_names <- unique(sorted_df$name)

# Step 2: Find missing power plant names in sorted_df compared to demo_df
missing_names <- setdiff(demo_names, sorted_names)

# Step 3: Check if there are missing power plant names
if (length(missing_names) > 0) {
  # Step 4: Append missing power plant names to sorted_df with NA values in Energy_MWh column
  missing_rows <- data.frame(Time = rep(NA, length(missing_names)),
                             name = missing_names,
                             Energy_MWh = rep(NA, length(missing_names)))
  sorted_df <- rbind(sorted_df, missing_rows)
}


```
# making new column named Month_Year w.r.t Time column
```{r}
# Create the Month_Year column
sorted_df$Month_Year <- paste0(format(sorted_df$Time, "%Y %b"))
# Create a new column Rs_per_MWh_FCA of type double (dbl) and assign it a default value (e.g., NA)
# sorted_df$Rs_per_MWh_FCA <- as.double(NA)

# Display the updated data frame
# sorted_df<-sorted_df[,-4]
str(sorted_df)

```
# rates for energy csv file
```{r}
# Specify the file path
file_path <- "Energy_in_Rs_per_MWh_FCA_July2021_June2022_Long_Format.csv"

# Read the CSV file and save it as a dataframe
rates_for_energy <- read.csv(file_path)

# Display the first few rows of the dataframe (optional)
head(rates_for_energy)

```
# populating rates_for_energy
```{r}
# Create a copy of the sorted_df dataframe
modified_df <- sorted_df

# Perform the left join based on "name" and "Month_Year" columns
modified_df <- left_join(modified_df, rates_for_energy, by = c("name", "Month_Year"))

# Populate the "Rs_per_MWh_FCA" column in modified_df with values from "Rs_per_MWh_FCA.y" if it's missing in "Rs_per_MWh_FCA.x"
modified_df$Rs_per_MWh_FCA <- ifelse(is.na(modified_df$Rs_per_MWh_FCA.x), modified_df$Rs_per_MWh_FCA.y, modified_df$Rs_per_MWh_FCA.x)

# Drop the unnecessary "Rs_per_MWh_FCA.y" and "Rs_per_MWh_FCA.x" columns
modified_df <- subset(modified_df, select = -c(Rs_per_MWh_FCA.y, Rs_per_MWh_FCA.x))

# Display the updated dataframe (optional)
head(modified_df)


```
# full join
```{r}
modified_df1<-merge(sorted_df, rates_for_energy, by = c("name", "Month_Year"),sort=F)
modified_df1=modified_df1[order(modified_df1$Time),]
```
# final output required is being save to csv
```{r}
filename <- "final_output_fiscal_2021_2022"
  write.csv(modified_df1, paste0(filename, ".csv"), row.names = FALSE, quote = FALSE)
```

```{r}
demo_df[format(demo_df$Time,"%Y-%m")=="2022-03",]
demo_df$Month_Year <- paste0(format(demo_df$Time, "%Y %b"))
test<-merge(demo_df, rates_for_energy, by= c("name", "Month_Year"),sort=F)
```
# sorted df in csv for supervisor
```{r}
filename <- "sorted_df_csv"
  write.csv(sorted_df, paste0(filename, ".csv"), row.names = FALSE, quote = FALSE)
```

